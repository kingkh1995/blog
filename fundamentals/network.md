# [首页](/blog/)

> **网络通信**

***

## *IO模型*

### BIO

同步阻塞IO，面向流，传统的模型，典型应用如Java的BIO。

应用进程使用**recvfrom**发起IO系统调用后，会一直阻塞直到内核缓存区的数据准备好，并将数据拷贝至用户空间。


### NIO

同步非阻塞IO，面向缓冲区，核心是Buffer（缓冲区）、Channel（通道）和Selector（多路复用器）。

应用进程仍然是使用**recvfrom**发起IO系统调用，但如果内核缓存区数据未准备好则立即返回错误标识，准备好了则将数据拷贝到用户空间，因此需要应用程序不断发起询问内核数据是否准备好。

### 多路复用IO

即Reactor模型，使用fd（文件句柄）绑定一个socket，**典型的如Linux的select、poll和epoll以及Java的NIO**。

多个应用进程的IO事件注册到一个复用器（select）上，然后使用一个进程调用该select，select会监听所有注册进来的IO事件，会一直阻塞直到任一个IO的数据在内核缓冲区中可用，select调用进程可以自己或通知注册进程来再次发起recvfrom读取内核缓冲区中准备好的数据。

- select：使用轮询方式，每次都需要把fd集合从用户态拷贝到内核态后，才能检查IO事件是否就绪；
- poll：方式与select一样，不过没有最大文件数限制，因为是使用链表结构存储fd；
- epoll：即event poll，虽然连接数有上限，但是很大。在Linux内核中有专门的epoll文件系统，**适用于监控大量的但大多数活跃度不高的fd，这样每次只需要将少量的文件句柄从内核态拷贝到用户态**。
  - epoll_create()：用于创建epoll对象，除了会使用红黑树存储注册的socket外，还使用链表保存准备就绪的IO事件，通过内核与用户mmap共享一块内存来实现的；
  - epoll_ctl()：向epoll对象中注册socket，同时会往内核注册一个回调函数，当socket上数据到达后，将其添加到事件链表中；
  - epoll_wait()：只需要从事件链表读取准备就绪的句柄即可。
        
### 信号驱动IO

应用进程发起一个IO操作，信号处理程序通过系统调用sigaction，往内核注册一个信号处理函数，然后请求即刻返回，当内核数据准备就绪后，就生成对应进程的SIGIO信号，通过信号处理程序通知应用线程可以调用recvfrom来读取数据。
    
### 异步IO

Proactor模型，属于异步操作，因为只有异步IO不需要应用进程自己调用recvfrom来读取数据，典型如Java的AIO。

应用进程发起一个aio_read请求之后直接返回，如果内核缓存区数据准备好了，内核主动拷贝数据到用户空间，完成后通过aio_read中指定的信号通知到应用进程。

***